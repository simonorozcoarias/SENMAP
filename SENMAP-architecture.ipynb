{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAb77yZ9fzMG",
    "outputId": "46d32c58-fb5d-4dfd-832a-eb4b0cc098e7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrUC-DAyylM3",
    "outputId": "88f7b4eb-b659-47f7-e094-10a62620dd90"
   },
   "outputs": [],
   "source": [
    "!pip install focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pafL7Li0jyXW"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import set_option\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow.keras.utils\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM\n",
    "import numpy as np \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sn \n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "import time as tm\n",
    "import datetime\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from numpy import argmax\n",
    "from numpy import round\n",
    "from focal_loss import BinaryFocalLoss\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6YMWWHwt-S8",
    "outputId": "455bab31-f63b-43d4-c543-4d99de2a2088"
   },
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffVqcOXHuJwy",
    "outputId": "92652a6e-acb3-4206-9360-55b468569c82"
   },
   "outputs": [],
   "source": [
    "pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HDwvpi-Jt398",
    "outputId": "9f486662-94ef-4980-80fc-99c3bfcfeeba"
   },
   "outputs": [],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kjLLME7WuNmW",
    "outputId": "e62d4d7d-1261-44a4-9c8a-0ccdccac5eec"
   },
   "outputs": [],
   "source": [
    "pip uninstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B83Ujj33uPr-",
    "outputId": "bdc8c39d-2b6c-4f58-8232-64e1bd6653bf"
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZhP0ZSpuR4z",
    "outputId": "65551405-4b9a-485f-ba25-88a9b0bdfac4"
   },
   "outputs": [],
   "source": [
    "pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkmxP-kivjGX"
   },
   "outputs": [],
   "source": [
    "y = np.load(\"/content/drive/Shareddrives/Experimentos_CNN/2_labels_DB.fa.filtered_center.npy\")\n",
    "y = y.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiefCArGvs36"
   },
   "outputs": [],
   "source": [
    "x = np.load(\"/content/drive/Shareddrives/Experimentos_CNN/2_labels_DB.fasta.filtered_center.npy\")\n",
    "x = x.astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hEBWcOxxnc9"
   },
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_test_dev, Y_train, Y_test_dev = train_test_split(x, y, test_size=validation_size,random_state=seed)\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X_test_dev, Y_test_dev, test_size=0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwIaTCnFyPuN",
    "outputId": "92c76edd-b5a3-4772-cbad-7df6b33b4f65"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6jWa_kWvFIp"
   },
   "outputs": [],
   "source": [
    "path_log_base = '/content/drive/Shareddrives/Experimentos_CNN/Estiven/8/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWtZvvDVvKu8"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpCRRnG_XZfh"
   },
   "outputs": [],
   "source": [
    "def metrics(Y_validation,predictions):\n",
    "    classes = len(np.unique(Y_validation))\n",
    "    print('Accuracy:', accuracy_score(Y_validation, predictions))\n",
    "    print('F1 score:', f1_score(Y_validation, predictions,average='weighted'))\n",
    "    print('Recall:', recall_score(Y_validation, predictions,average='weighted'))\n",
    "    print('Precision:', precision_score(Y_validation, predictions, average='weighted'))\n",
    "    print('\\n clasification report:\\n', classification_report(Y_validation, predictions))\n",
    "    print('\\n confusion matrix:\\n',confusion_matrix(Y_validation, predictions))\n",
    "    #Creamos la matriz de confusión\n",
    "    snn_cm = confusion_matrix(Y_validation, predictions)\n",
    "\n",
    "    # Visualizamos la matriz de confusión\n",
    "    snn_df_cm = pd.DataFrame(snn_cm, range(classes), range(classes))  \n",
    "    plt.figure(figsize = (20,14))  \n",
    "    sn.set(font_scale=1.4) #for label size  \n",
    "    sn.heatmap(snn_df_cm, annot=True, annot_kws={\"size\": 25},fmt='',cmap=\"YlOrRd\") # font size\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1AWzFsNyNeW"
   },
   "outputs": [],
   "source": [
    "def SENMAP():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Inputs\n",
    "    inputs = tf.keras.Input(shape=(X_train.shape[1], X_train.shape[2], 1), name=\"input_1\")\n",
    "    \n",
    "    # layer 1\n",
    "    layers = tf.keras.layers.Conv2D(32, (5, 51),strides=(1, 1) ,activation=tf.keras.layers.LeakyReLU(0.01), kernel_regularizer=regularizers.l1_l2(0.0000, 0.000), bias_regularizer=regularizers.l1_l2(0.0000, 0.0000), use_bias=True)(inputs)\n",
    "    layers = tf.keras.layers.SpatialDropout2D(0.2)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((1, 9), strides=None)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "\n",
    "    # layer 2\n",
    "    layers = tf.keras.layers.Conv2D(64, (1, 31),strides=(1, 1), activation=tf.keras.layers.LeakyReLU(0.01),  kernel_regularizer=regularizers.l1_l2(0.0000, 0.000), bias_regularizer=regularizers.l1_l2(0.0000, 0.0000), use_bias=True)(layers)\n",
    "    layers = tf.keras.layers.SpatialDropout2D(0.2)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((1, 9), strides=None)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(axis=1, momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "\n",
    "    # layer 3\n",
    "    layers = tf.keras.layers.Conv2D(128, (1, 11),strides=(1, 1), activation=tf.keras.layers.LeakyReLU(0.01),  kernel_regularizer=regularizers.l1_l2(0.0000, 0.000), bias_regularizer=regularizers.l1_l2(0.0000, 0.0000), use_bias=True)(layers)\n",
    "    layers = tf.keras.layers.SpatialDropout2D(0.2)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((1, 7), strides=None)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(axis=1, momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "    \n",
    "    # layer 4\n",
    "    layers = tf.keras.layers.Conv2D(256, (1, 5),strides=(1, 1), activation=tf.keras.layers.LeakyReLU(0.01),  kernel_regularizer=regularizers.l1_l2(0.0000, 0.000), bias_regularizer=regularizers.l1_l2(0.0000, 0.0000), use_bias=True)(layers)\n",
    "    layers = tf.keras.layers.SpatialDropout2D(0.2)(layers)\n",
    "    layers = tf.keras.layers.AveragePooling2D((1, 5), strides=None)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(axis=1, momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "\n",
    "    # layer 5\n",
    "    layers = tf.keras.layers.Flatten()(layers)\n",
    "\n",
    "    # layer 6\n",
    "    layers = tf.keras.layers.Dense(300,activation=tf.keras.layers.LeakyReLU(0.01), kernel_regularizer=regularizers.l1_l2(0.0003, 0.001), bias_regularizer=regularizers.l1(0.001))(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "\n",
    "    # layer 7\n",
    "    layers = tf.keras.layers.Dense(300,activation=tf.keras.layers.LeakyReLU(0.01), kernel_regularizer=regularizers.l1_l2(0.0003, 0.001), bias_regularizer=regularizers.l1(0.001))(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers = tf.keras.layers.BatchNormalization(momentum=0.6, epsilon=0.001, scale=False)(layers)\n",
    "\n",
    "    # layer 8\n",
    "    layers = tf.keras.layers.Dense(300,activation=tf.keras.layers.LeakyReLU(0.01), kernel_regularizer=regularizers.l1_l2(0.0003, 0.001), bias_regularizer=regularizers.l1(0.001))(layers)\n",
    "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
    "    layers=tf.keras.layers.BatchNormalization(momentum=0.6, epsilon=0.001,  scale=False)(layers)\n",
    "\n",
    "    # layer end\n",
    "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
    "    \n",
    "    # model generation\n",
    "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
    "    \n",
    "    # optimizer\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "    # loss function\n",
    "    loss_fn = BinaryFocalLoss(gamma=2)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss_fn, optimizer=opt, metrics=[f1_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9KfxKurXRVR"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        loss = BinaryFocalLoss(gamma=2),\n",
    "        #loss=tf.keras.losses.BinaryFocalCrossentropy(gamma=2.0, from_logits=True),\n",
    "        #loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            #keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "            #keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\", dtype=None),\n",
    "            #keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_f1_m\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        #x=X_train,\n",
    "        y=one_hot_labels_train,\n",
    "        y = Y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=(X_dev, one_hot_labels_validation),verbose=1)\n",
    "        #validation_data=(X_dev, Y_dev),verbose=1)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7p1KIKMvZPC"
   },
   "outputs": [],
   "source": [
    "one_hot_labels_train = tf.keras.utils.to_categorical(Y_train, num_classes=2)\n",
    "one_hot_labels_validation = tf.keras.utils.to_categorical(Y_dev, num_classes=2)\n",
    "one_hot_labels_test = tf.keras.utils.to_categorical(Y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SENMAP()\n",
    "model.summary()\n",
    "history = run_experiment(model)\n",
    "\n",
    "\n",
    "acc=history.history['accuracy']\n",
    "np.save('/home/rtabares/Transformer/accuracy_SENMAP_completeDB.npy',acc)\n",
    "val_acc=history.history['val_accuracy']\n",
    "np.save('/home/rtabares/Transformer/val_accuracy_SENMAP_completeDB.npy',val_acc)\n",
    "loss=history.history['loss']\n",
    "np.save('/home/rtabares/Transformer/loss_SENMAP_completeDB.npy',loss)\n",
    "val_loss=history.history['val_loss']\n",
    "np.save('/home/rtabares/Transformer/val_los_SENMAP_completeDBnpy',val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['val_accuracy','train_accuracy'], loc='lower right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Epoch vs accuracy')\n",
    "plt.show()\n",
    "plt.savefig('/home/rtabares/Transformer/Train_Curve_80000.png',  bbox_inches='tight',dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eINgiZTz83t9",
    "outputId": "b02847d0-5d46-4a59-92d6-6e946573f1fd"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train, one_hot_labels_train, verbose=0)\n",
    "print(\"Baseline Error train: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_dev, one_hot_labels_validation, verbose=0)\n",
    "print(\"Baseline Error dev: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, one_hot_labels_test, verbose=0)\n",
    "print(\"Baseline Error test: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "predictions = model.predict(X_train)\n",
    "metrics(Y_train, [argmax(x) for x in predictions])\n",
    "\n",
    "predictions = model.predict(X_dev)\n",
    "metrics(Y_dev, [argmax(x) for x in predictions])\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "metrics(Y_test, [argmax(x) for x in predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krsvMPkZ9Qpx"
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1).split(X_train, Y_train)\n",
    "\n",
    "scores=[]\n",
    "for k, (train,test) in enumerate(kfold):\n",
    "  #tf.keras.backend.clear_session()\n",
    "  model = SENMAP()\n",
    "  compile_model(model)\n",
    "  model.fit(X_train[train], Y_train[train], batch_size=128, epochs=200, verbose=0)\n",
    "  score = accuracy_score(Y_train[test], [argmax(x) for x in model.predict(X_train[test])])\n",
    "  scores.append(score)\n",
    "\n",
    "print('Cv accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "print(scores)\n",
    "np.save('/home/rtabares/Transformer/scores_SENMAP_completeDB.npy',scores)\n",
    "\n",
    "\n",
    "#Informacion resultado\n",
    "\n",
    "table = pd.DataFrame(columns=['Predicciones','Salidas_Esperadas','Resultado'])\n",
    "pred = [argmax(x) for x in predictions]\n",
    "table['Predicciones'] = pred\n",
    "table['Salidas_Esperadas'] = Y_test\n",
    "\n",
    "for i in range(len(pred)):\n",
    "  if table['Predicciones'][i] == 1:\n",
    "    table['Predicciones'][i] = True\n",
    "  else:\n",
    "    table['Predicciones'][i] = False\n",
    "\n",
    "for j in range(len(pred)):\n",
    "  if table['Predicciones'][j] and table['Salidas_Esperadas'][j]:\n",
    "    table['Resultado'][j] = True\n",
    "  else:\n",
    "    table['Resultado'][j] = False\n",
    "np.save('/home/rtabares/Transformer/SENMAP_predicciones_completeDB.npy',table)\n",
    "table = table.drop(table[table['Resultado']==True].index)\n",
    "#print(table_fil.index)\n",
    "np.save('/home/rtabares/Transformer/SENMAP_indices_completeDB.npy',table.index)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copia de Pruebas2d_DL_Estiven.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
